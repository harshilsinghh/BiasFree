{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf28150-3f4d-4dc0-a1c6-8c39c1d189ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from safetensors.torch import load_file\n",
    "import joblib\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8547767f-eb6f-4e1f-abbc-7819c0f62f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required NLTK data\n",
    "nltk.download('punkt', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33beb0c-e3bc-460e-bfed-50f7f3123c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device for computation\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c2e277-fed7-4e0f-82a4-4b6b836ff6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model paths and hyperparameters\n",
    "LSTM_MODEL_DIR = 'utbert'\n",
    "GLOVE_PATH = \"glove.6B.100d.txt\"\n",
    "MAX_LEN = 100\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 2\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    \"\"\"Custom Dataset class for text data.\"\"\"\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx]\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"LSTM-based text classifier with pre-trained embeddings.\"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, embeddings=None):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        if embeddings is not None:\n",
    "            self.embedding.weight = nn.Parameter(embeddings)\n",
    "            self.embedding.weight.requires_grad = True\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, num_layers=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        hidden = self.dropout(hidden[-1])\n",
    "        return self.fc(hidden)\n",
    "\n",
    "def load_glove_embeddings(glove_path, word_to_idx, embedding_dim):\n",
    "    \"\"\"Load GloVe embeddings for the vocabulary.\"\"\"\n",
    "    embeddings = np.zeros((len(word_to_idx), embedding_dim), dtype=np.float32)\n",
    "    embeddings[1] = np.random.normal(0, 0.1, embedding_dim)  # <UNK>\n",
    "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word, vector = values[0], np.array(values[1:], dtype=np.float32)\n",
    "            if word in word_to_idx:\n",
    "                embeddings[word_to_idx[word]] = vector\n",
    "    return torch.tensor(embeddings, dtype=torch.float32)\n",
    "\n",
    "def preprocess_text(text, word_to_idx, max_len=MAX_LEN):\n",
    "    \"\"\"Convert text to tensor of token indices for LSTM.\"\"\"\n",
    "    tokens = word_tokenize(str(text).lower())\n",
    "    indices = [word_to_idx.get(token, word_to_idx[\"<UNK>\"]) for token in tokens][:max_len]\n",
    "    indices += [word_to_idx[\"<PAD>\"]] * (max_len - len(indices)) if len(indices) < max_len else []\n",
    "    return torch.tensor([indices], dtype=torch.long).to(device)\n",
    "\n",
    "def get_bert_predictions(texts, batch_size=16):\n",
    "    \"\"\"Generate BERT predictions in batches.\"\"\"\n",
    "    dataset = TextDataset(texts)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    all_probs = []\n",
    "    \n",
    "    bert_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_texts in dataloader:\n",
    "            inputs = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            outputs = bert_model(**inputs)\n",
    "            probs = torch.softmax(outputs.logits, dim=1)[:, 1].cpu().numpy()\n",
    "            all_probs.extend(probs)\n",
    "            torch.cuda.empty_cache()\n",
    "    return np.array(all_probs)\n",
    "\n",
    "def load_glove_dict(glove_path):\n",
    "    \"\"\"Load GloVe embeddings into a dictionary.\"\"\"\n",
    "    glove = {}\n",
    "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            glove[values[0]] = np.array(values[1:], dtype=np.float32)\n",
    "    return glove\n",
    "\n",
    "def texts_to_glove_embeddings(texts, glove):\n",
    "    \"\"\"Convert texts to averaged GloVe embeddings.\"\"\"\n",
    "    embeddings = np.zeros((len(texts), EMBEDDING_DIM))\n",
    "    for i, text in enumerate(texts):\n",
    "        tokens = word_tokenize(str(text).lower())\n",
    "        vectors = [glove.get(word, np.zeros(EMBEDDING_DIM)) for word in tokens]\n",
    "        if vectors:\n",
    "            embeddings[i] = np.mean(vectors, axis=0)\n",
    "    return embeddings\n",
    "\n",
    "def get_logreg_predictions(texts, glove, lr_model):\n",
    "    \"\"\"Generate Logistic Regression predictions.\"\"\"\n",
    "    embeddings = texts_to_glove_embeddings(texts, glove)\n",
    "    return lr_model.predict_proba(embeddings)[:, 1]\n",
    "\n",
    "def get_lstm_predictions(texts, batch_size=32):\n",
    "    \"\"\"Generate LSTM predictions in batches.\"\"\"\n",
    "    dataset = TextDataset(texts)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    all_probs = []\n",
    "    \n",
    "    lstm_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_texts in dataloader:\n",
    "            inputs = preprocess_texts(batch_texts, word_to_idx)\n",
    "            logits = lstm_model(inputs)\n",
    "            probs = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()\n",
    "            all_probs.extend(probs)\n",
    "            torch.cuda.empty_cache()\n",
    "    return np.array(all_probs)\n",
    "\n",
    "def evaluate_model(y_true, y_pred, y_prob, model_name):\n",
    "    \"\"\"Evaluate model performance with various metrics.\"\"\"\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred),\n",
    "        \"F1-Score\": f1_score(y_true, y_pred),\n",
    "        \"AUC-ROC\": roc_auc_score(y_true, y_prob)\n",
    "    }\n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['Unbiased', 'Biased']))\n",
    "\n",
    "def stacking_predict(texts, bert_batch_size=16, lstm_batch_size=32):\n",
    "    \"\"\"Predict bias using the stacking ensemble.\"\"\"\n",
    "    bert_probs = get_bert_predictions(texts, bert_batch_size)\n",
    "    logreg_probs = get_logreg_predictions(texts, glove, lr_model)\n",
    "    lstm_probs = get_lstm_predictions(texts, lstm_batch_size)\n",
    "    meta_features = np.column_stack((bert_probs, logreg_probs, lstm_probs))\n",
    "    final_preds = meta_model.predict(meta_features)\n",
    "    final_probs = meta_model.predict_proba(meta_features)[:, 1]\n",
    "    return final_preds, final_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3662513b-48b9-441d-9b2a-6476e7b5682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models and resources\n",
    "tokenizer = BertTokenizer.from_pretrained(LSTM_MODEL_DIR)\n",
    "bert_model = BertForSequenceClassification.from_pretrained(LSTM_MODEL_DIR).to(device).eval()\n",
    "lr_model = joblib.load('logreg_model.pkl')\n",
    "word_to_idx = joblib.load('word_to_idx.pkl')\n",
    "embeddings = load_glove_embeddings(GLOVE_PATH, word_to_idx, EMBEDDING_DIM)\n",
    "lstm_model = LSTMClassifier(len(word_to_idx), EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, embeddings)\n",
    "lstm_model.load_state_dict(torch.load('best_lstm_model.pt', map_location=device))\n",
    "lstm_model.to(device).eval()\n",
    "glove = load_glove_dict(GLOVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b279de-da8d-4793-9d8d-f5e5f5b839ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "data = pd.read_csv('train.csv')\n",
    "data = data.drop(columns=data.columns[0]).rename(columns={'0': 'text', '1': 'label'})\n",
    "train, test = train_test_split(data, test_size=0.2, shuffle=True, stratify=data['label'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccd1965-5a5e-47ae-bc25-ef21a73be347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare validation and test sets\n",
    "val_texts, val_labels = train['text'].tolist(), train['label'].values\n",
    "test_texts, test_labels = test['text'].tolist(), test['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40ce2d3-1870-4efb-b2b6-3da434245b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate meta-features\n",
    "bert_preds_val = get_bert_predictions(val_texts)\n",
    "logreg_preds_val = get_logreg_predictions(val_texts, glove, lr_model)\n",
    "lstm_preds_val = get_lstm_predictions(val_texts)\n",
    "meta_features_val = np.column_stack((bert_preds_val, logreg_preds_val, lstm_preds_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc500c58-eeb9-402c-964e-4c03c3a8ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train meta-model\n",
    "meta_model = RandomForestClassifier(\n",
    "    n_estimators=250,\n",
    "    max_depth=12,\n",
    "    min_samples_split=5,\n",
    "    class_weight='balanced_subsample',\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda856a9-fdb1-42b0-9832-7f4b92a48c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model.fit(meta_features_val, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a754be36-6910-4bd0-bc1a-fd889a04ec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set predictions\n",
    "bert_preds_test = get_bert_predictions(test_texts)\n",
    "logreg_preds_test = get_logreg_predictions(test_texts, glove, lr_model)\n",
    "lstm_preds_test = get_lstm_predictions(test_texts)\n",
    "meta_features_test = np.column_stack((bert_preds_test, logreg_preds_test, lstm_preds_test))\n",
    "final_preds = meta_model.predict(meta_features_test)\n",
    "final_probs = meta_model.predict_proba(meta_features_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ff36c-2164-495b-9d3d-1e7baf3676cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate stacking ensemble\n",
    "evaluate_model(test_labels, final_preds, final_probs, \"Stacking Ensemble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89632611-838a-4363-8845-c72f02b3fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example inference\n",
    "sample_text = \"Sample Text\"\n",
    "preds, probs = stacking_predict([sample_text])\n",
    "print(f\"\\nText: {sample_text}\")\n",
    "print(f\"Predicted Label: {'Biased' if preds[0] == 1 else 'Unbiased'}\")\n",
    "print(f\"Probability of Bias: {probs[0]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
