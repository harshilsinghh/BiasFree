{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96bb562-4700-4310-8e76-0dbb766f3b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc48590-22c0-47c3-b63c-61fe467a75e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download necessary NLTK tokenizers\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d818ba-22c4-4443-89f8-37082e6a03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = 'glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1f3810-6c00-4693-887d-936db2974f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('train.csv', index_col=None)\n",
    "df.drop(df.columns[0], axis=1, inplace=True)  # Remove unnecessary index column\n",
    "df = df.rename(columns={'0': 'comment_text', '1': 'label'})  # Rename columns for clarity\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "train_df_balanced, val_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=True, stratify=df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd0d653-1747-4418-80b0-462503081955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048cdd8a-72de-49d4-ba01-43280026bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "output_dim = 2\n",
    "max_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdccfe15-7d53-4d74-868d-6246da78d587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build vocabulary from training data and GloVe embeddings\n",
    "def build_vocab(texts, glove_path, min_freq=1):\n",
    "    word_freq = Counter()\n",
    "    for text in texts:\n",
    "        tokens = word_tokenize(str(text).lower())\n",
    "        word_freq.update(tokens)\n",
    "    \n",
    "    word_to_idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "    idx = 2\n",
    "    for word, freq in word_freq.items():\n",
    "        if freq >= min_freq and word not in word_to_idx:\n",
    "            word_to_idx[word] = idx\n",
    "            idx += 1\n",
    "    \n",
    "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            word = line.split()[0]\n",
    "            if word not in word_to_idx:\n",
    "                word_to_idx[word] = idx\n",
    "                idx += 1\n",
    "    \n",
    "    return word_to_idx\n",
    "\n",
    "# Function to load pre-trained GloVe embeddings\n",
    "def load_glove_embeddings(glove_path, word_to_idx, embedding_dim):\n",
    "    embeddings = np.zeros((len(word_to_idx), embedding_dim), dtype=np.float32)\n",
    "    embeddings[1] = np.random.normal(0, 0.1, embedding_dim)  # Initialize <UNK> embeddings\n",
    "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            if word in word_to_idx:\n",
    "                idx = word_to_idx[word]\n",
    "                embeddings[idx] = np.array(values[1:], dtype=np.float32)\n",
    "    return torch.tensor(embeddings, dtype=torch.float32)\n",
    "\n",
    "# Custom dataset class for handling text data\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, dataframe, word_to_idx, max_len=100):\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.max_len = max_len\n",
    "        self.texts = dataframe['comment_text'].values\n",
    "        self.labels = dataframe['label'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx]).lower()\n",
    "        label = self.labels[idx]\n",
    "        tokens = word_tokenize(text)\n",
    "        indices = [self.word_to_idx.get(token, self.word_to_idx[\"<UNK>\"]) for token in tokens][:self.max_len]\n",
    "        if len(indices) < self.max_len:\n",
    "            indices += [self.word_to_idx[\"<PAD>\"]] * (self.max_len - len(indices))\n",
    "        return torch.tensor(indices, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Define LSTM model class\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, embeddings=None):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        if embeddings is not None:\n",
    "            self.embedding.weight = nn.Parameter(embeddings)\n",
    "            self.embedding.weight.requires_grad = True\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, num_layers=1, dropout=0.0)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        hidden = self.dropout(hidden[-1])\n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a7c23f-eadb-4097-8e34-9fcacaeeb289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary and load embeddings\n",
    "word_to_idx = build_vocab(train_df_balanced['comment_text'], glove_path)\n",
    "embeddings = load_glove_embeddings(glove_path, word_to_idx, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3610f5d-fced-42e0-823f-bc4da818fcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset loaders\n",
    "train_dataset = TextDataset(train_df_balanced, word_to_idx, max_len)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = TextDataset(val_df, word_to_idx, max_len)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763f9971-1028-4689-8c49-99a555e90561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "vocab_size = len(word_to_idx)\n",
    "model = LSTMClassifier(vocab_size, embedding_dim, hidden_dim, output_dim, embeddings).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ac9aa5-ff02-41d8-87fd-76e2c18cc394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(model, val_loader, device, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch[0].to(device)\n",
    "            labels = batch[1].to(device).long()\n",
    "            outputs = model(input_ids)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs)\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    \n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef1c8be-a8a2-4aff-86e5-2f806652ac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "evaluate_model(model, val_loader, device, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ffc3f0-1882-423e-a4ef-1cc8f6da75b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, word_to_idx, max_len=100):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        text = \"<UNK>\"\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    indices = [word_to_idx.get(token, word_to_idx[\"<UNK>\"]) for token in tokens][:max_len]\n",
    "    if len(indices) < max_len:\n",
    "        indices += [word_to_idx[\"<PAD>\"]] * (max_len - len(indices))\n",
    "    return torch.tensor([indices], dtype=torch.long).to(device)\n",
    "\n",
    "def identify_biased_sentences_lstm(text, model, word_to_idx, threshold=0.3, max_len=100):\n",
    "    try:\n",
    "        sentences = sent_tokenize(text)\n",
    "        if not sentences:\n",
    "            raise ValueError(\"No sentences detected in the input text.\")\n",
    "        \n",
    "        biased_sentences = []\n",
    "        scores = []\n",
    "        labels = []\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for sentence in sentences:\n",
    "                input_tensor = preprocess_text(sentence, word_to_idx, max_len)\n",
    "                logits = model(input_tensor)\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                prob_biased = probs[0, 1].item()  # Class 1 = biased\n",
    "                label = 1 if prob_biased >= threshold else 0\n",
    "                \n",
    "                scores.append(prob_biased)\n",
    "                labels.append(label)\n",
    "                if label == 1:\n",
    "                    biased_sentences.append(sentence)\n",
    "        \n",
    "        return biased_sentences, scores, labels\n",
    "    except Exception as e:\n",
    "        print(f\"Error during inference: {e}\")\n",
    "        return [], [], []\n",
    "\n",
    "# Load and run inference\n",
    "try:\n",
    "    model.load_state_dict(torch.load('lstm_bias_model.pth', map_location=device, weights_only=True))\n",
    "    model.to(device)\n",
    "except FileNotFoundError:\n",
    "    print(\"Model file 'lstm_bias_model.pth' not found.\")\n",
    "    exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17551dc5-2c03-4fa5-b5a5-bc0d915a7192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample inference\n",
    "sample_text = '''Test text'''\n",
    "\n",
    "biased_sentences, scores, labels = identify_biased_sentences_lstm(sample_text, model, word_to_idx, threshold=0.3)\n",
    "\n",
    "print(\"\\n=== Inference Results ===\")\n",
    "for sentence, score, label in zip(sent_tokenize(sample_text), scores, labels):\n",
    "    print(f\"Sentence: '{sentence}'\")\n",
    "    print(f\"Score (Prob Biased): {score:.4f}, Label: {'Biased' if label == 1 else 'Unbiased'}\")\n",
    "    print()\n",
    "\n",
    "print(\"Biased Sentences Only:\")\n",
    "for sentence in biased_sentences:\n",
    "    print(f\"- {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c6799-599c-4802-9559-1dfd85616c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and vocabulary\n",
    "torch.save(model.state_dict(), 'lstm_model.pth')\n",
    "joblib.dump(word_to_idx, 'word_to_idx.pkl')\n",
    "\n",
    "# Provide download links for saved models\n",
    "from IPython.display import FileLink\n",
    "display(FileLink('lstm_model.pth'))\n",
    "display(FileLink('word_to_idx.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa77f3e-6c2b-4a1c-b372-fa9c33239f64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
